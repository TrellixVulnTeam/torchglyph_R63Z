{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to TorchGlyph Data Processor Combinators for Natural Language Processing Installation Simply run this command in your terminal, pip install torchglyph Quickstart The atomic data processor of TorchGlyph is called Proc . Compose operator + is provided to produce complex Proc by composing two simple Proc s. ToLower() + ReplaceDigits(repl_token='<digits>') Composed Proc s act like data Pipe lines, where raw textual data is processed incrementally. According to the stages, they are roughly categorized into four-groups: pre for processing before building vocabulary; vocab for building and updating vocabulary ; post for precessing after building vocabulary; batch for collating examples to build batches . Defining the Pipe s of your dataset is the first step to build a dataset, you can build it from scratch, class PackedIdxSeqPipe(Pipe): def __init__(self, device, dtype=torch.long) -> None: super(PackedIdxSeqPipe, self).__init__( pre=None, vocab=None, post=ToTensor(dtype=dtype), batch=PackSeq(enforce_sorted=False) + ToDevice(device=device), ) or you can simply manipulate existing Pipe s by calling .with_ method. class PackedTokSeqPipe(PackedIdxSeqPipe): def __init__(self, device, unk_token, special_tokens=(), threshold=THRESHOLD, dtype=torch.long) -> None: super(PackedTokSeqPipe, self).__init__(device=device, dtype=dtype) self.with_( pre=UpdateCounter(), vocab=[ BuildVocab(unk_token=unk_token, pad_token=None, special_tokens=special_tokens), StatsVocab(threshold=threshold), ], post=Numbering() + ..., )","title":"Home"},{"location":"#welcome-to-torchglyph","text":"Data Processor Combinators for Natural Language Processing","title":"Welcome to TorchGlyph"},{"location":"#installation","text":"Simply run this command in your terminal, pip install torchglyph","title":"Installation"},{"location":"#quickstart","text":"The atomic data processor of TorchGlyph is called Proc . Compose operator + is provided to produce complex Proc by composing two simple Proc s. ToLower() + ReplaceDigits(repl_token='<digits>') Composed Proc s act like data Pipe lines, where raw textual data is processed incrementally. According to the stages, they are roughly categorized into four-groups: pre for processing before building vocabulary; vocab for building and updating vocabulary ; post for precessing after building vocabulary; batch for collating examples to build batches . Defining the Pipe s of your dataset is the first step to build a dataset, you can build it from scratch, class PackedIdxSeqPipe(Pipe): def __init__(self, device, dtype=torch.long) -> None: super(PackedIdxSeqPipe, self).__init__( pre=None, vocab=None, post=ToTensor(dtype=dtype), batch=PackSeq(enforce_sorted=False) + ToDevice(device=device), ) or you can simply manipulate existing Pipe s by calling .with_ method. class PackedTokSeqPipe(PackedIdxSeqPipe): def __init__(self, device, unk_token, special_tokens=(), threshold=THRESHOLD, dtype=torch.long) -> None: super(PackedTokSeqPipe, self).__init__(device=device, dtype=dtype) self.with_( pre=UpdateCounter(), vocab=[ BuildVocab(unk_token=unk_token, pad_token=None, special_tokens=special_tokens), StatsVocab(threshold=threshold), ], post=Numbering() + ..., )","title":"Quickstart"}]}